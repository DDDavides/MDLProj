{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from tensorflow import keras as k\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# %pip install d2l==1.0.0a1.post0\n",
    "from d2l import tensorflow as d2l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./input/dataset.csv')\n",
    "# dataImputed = pd.read_csv('./input/datasetImputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã¨ stata riscritta una funzione di reshape inutile \n",
    "# e.g. (a_prev=x_train, season=trn_ssn)\n",
    "def reshape_to_inputshape(a_prev,season):\n",
    "    totalMatches = len(season)*38\n",
    "    input_step = int(a_prev.shape[0]/totalMatches)\n",
    "    prev_f = a_prev.shape[1]\n",
    "    return np.reshape(a_prev, (totalMatches, input_step, prev_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['HomeTeam', 'AwayTeam', \n",
    "            'HTeamEloScore', 'ATeamEloScore', \n",
    "            'HTdaysSinceLastMatch', 'ATdaysSinceLastMatch', \n",
    "            'HTW_rate', 'ATW_rate', 'ATD_rate', 'HTD_rate', \n",
    "            '7_HTW_rate', '12_HTW_rate', '7_ATW_rate', '12_ATW_rate', \n",
    "            '7_HTD_rate', '12_HTD_rate', '7_ATD_rate', '12_ATD_rate',\n",
    "            '7_HTL_rate', '12_HTL_rate', '7_ATL_rate', '12_ATL_rate',\n",
    "            '5_HTHW_rate', '5_ATAW_rate']\n",
    "\n",
    "X = pd.get_dummies(data[features])\n",
    "\n",
    "# Se non cambiamo nulla il OneHotEncoder assegna:\n",
    "# A -> 1 0 0\n",
    "# D -> 0 1 0\n",
    "# H -> 0 0 1\n",
    "y = data[['FTR']].to_numpy().ravel().reshape(-1, 1)\n",
    "y = OneHotEncoder(sparse=False).fit_transform(y)\n",
    "X_imputed = SimpleImputer().fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ssn = [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]\n",
    "trn_ssn_len = len(trn_ssn)\n",
    "tst_ssn = [2016,2017,2018] \n",
    "tst_ssn_len = len(tst_ssn)\n",
    "\n",
    "test_size = float(tst_ssn_len)/(tst_ssn_len+trn_ssn_len)\n",
    "\n",
    "#Split X and Y into training and Test Sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_imputed, y, shuffle=False, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_step(a_prev,season):\n",
    "    a_prev = a_prev[np.newaxis, ...]\n",
    "    totalMatches = len(season)*38\n",
    "\n",
    "    prev_f = a_prev.shape[2]\n",
    "    input_step = int(a_prev.shape[1]/totalMatches)\n",
    "    step = 0\n",
    "    a_new = np.zeros((totalMatches, input_step, prev_f))\n",
    "    for i in range(totalMatches):\n",
    "        # rows divise in porzioni di totalMatches rows\n",
    "        step += input_step\n",
    "        \n",
    "        # per tutte le righe nell'intervallo di righe che stiamo guardando ora \n",
    "        # va in ogni porzione di righe di volta in volta\n",
    "        for j in range(step-input_step,step):\n",
    "\n",
    "            # per ogni colonna\n",
    "            for k in range(prev_f):\n",
    "                a_new[i, j - input_step * i, k] = a_prev[:, j, k]\n",
    "    \n",
    "    return a_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup XY to have 10 game steps\n",
    "lstm_x_train = reshape_to_inputshape(x_train,trn_ssn)\n",
    "lstm_y_train = reshape_to_inputshape(y_train,trn_ssn)\n",
    "# y_train = np.moveaxis(y_train, 0, 1)\n",
    "\n",
    "lstm_x_test = reshape_to_inputshape(x_test,tst_ssn)\n",
    "lstm_y_test = reshape_to_inputshape(y_test,tst_ssn)\n",
    "# y_test = np.moveaxis(y_test, 0, 1)\n",
    "\n",
    "Tx = lstm_x_train.shape[1] #Time steps\n",
    "Ty = lstm_y_train.shape[0] #Time Steps\n",
    "\n",
    "num_features = lstm_x_train.shape[2] #Features per step\n",
    "inputs = tf.keras.Input(shape=(Tx, num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304, 10, 94)\n",
      "(304, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "print(lstm_x_train.shape)\n",
    "print(lstm_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prova di tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 18)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.random.normal((32, 10, 8))\n",
    "lstm = tf.keras.layers.LSTM(18)\n",
    "output = lstm(inputs)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.04938694  0.20068401]\n",
      " [-0.01805884  0.34465146]\n",
      " [ 0.00431494  0.44729358]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([[[0, 1], [0, 1]], [[1, 2], [1, 2]], [[2, 3], [2, 3]]], dtype=np.float64)\n",
    "lstm = k.models.Sequential([\n",
    "    tf.keras.layers.LSTM(2)\n",
    "])\n",
    "out = lstm(inputs)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = tf.keras.models.Sequential([\n",
    "    k.layers.Dense(4000),\n",
    "    k.layers.Dropout(.7),\n",
    "    k.layers.Dense(100),\n",
    "    k.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (3040, 4000)              380000    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (3040, 4000)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (3040, 100)               400100    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (3040, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 780,403\n",
      "Trainable params: 780,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MLP.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=[tf.keras.metrics.Accuracy()]\n",
    ")\n",
    "MLP(x_train)\n",
    "MLP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (3040, 94) for input KerasTensor(type_spec=TensorSpec(shape=(3040, 94), dtype=tf.float64, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 10, 94).\n",
      "WARNING:tensorflow:Model was constructed with shape (3040, 94) for input KerasTensor(type_spec=TensorSpec(shape=(3040, 94), dtype=tf.float64, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 10, 94).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 12:58:04.792372: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 31ms/step - loss: 23.3819 - accuracy: 0.2654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3175d8370>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.fit(lstm_x_train, lstm_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifieri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Classifier\n",
      "Train Score:  0.6302631578947369\n",
      "Test Score:  0.22017543859649122\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=2, random_state=2)\n",
    "forest = forest.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Forest Model Metrics\n",
    "print(\"Forest Classifier\")\n",
    "print(\"Train Score: \", forest.score(x_train, y_train))\n",
    "print(\"Test Score: \", forest.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Classifiers Best Score:  0.4305921052631579\n",
      "Forest Classifiers Best Params:  {'max_depth': 8, 'n_estimators': 1, 'random_state': 1}\n",
      "Forest Classifiers Best Params:  RandomForestClassifier(max_depth=8, n_estimators=1, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "m = 5\n",
    "max_depth = 10\n",
    "forests = []\n",
    "grid = [{\"n_estimators\": list(range(1, n)), \"random_state\": list(range(0, m)), \"max_depth\": list(range(1, max_depth))}]\n",
    "gridSearch = GridSearchCV(RandomForestClassifier(), param_grid=grid, n_jobs=10, return_train_score=True)\n",
    "gridSearch.fit(x_train, y_train)\n",
    "# for i in range(1, n+1):\n",
    "#     for j in range(m):\n",
    "#         forest = RandomForestClassifier(n_estimators=i, random_state=j)\n",
    "#         forest = forest.fit(x_train, y_train)\n",
    "#         forests.append(forest)\n",
    "#         print(\"Forest Classifier, n_estimators: \", i, \"random_state: \", j)\n",
    "#         print(\"Train Score: \", forest.score(x_train, y_train))\n",
    "#         print(\"Test Score: \", forest.score(x_test, y_test))\n",
    "\n",
    "# #Forest Model Metrics\n",
    "# print(\"Forest Classifier\")\n",
    "# print(\"Train Score: \", forest.score(x_train, y_train))\n",
    "# print(\"Test Score: \", forest.score(x_test, y_test))\n",
    "print(\"Forest Classifiers Best Score: \", gridSearch.best_score_)\n",
    "print(\"Forest Classifiers Best Params: \", gridSearch.best_params_)\n",
    "print(\"Forest Classifiers Best Params: \", gridSearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prova = reshape_to_inputshape(x_train, trn_ssn)\n",
    "y_prova = reshape_to_inputshape(y_train, trn_ssn)\n",
    "x_prova_test = reshape_to_inputshape(x_test, tst_ssn)\n",
    "y_prova_test = reshape_to_inputshape(y_test, tst_ssn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 12:58:15.442809: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-05 12:58:15.629466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/10 [==>...........................] - ETA: 16s - loss: 6.6942 - accuracy: 0.3583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 12:58:15.922706: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 54ms/step - loss: 4.7425 - accuracy: 0.2916\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 2.5536 - accuracy: 0.1901\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 2.1376 - accuracy: 0.1660\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 2.3375 - accuracy: 0.1516\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.2665 - accuracy: 0.1308\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.9680 - accuracy: 0.1011\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.8839 - accuracy: 0.0861\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.8653 - accuracy: 0.0819\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.9449 - accuracy: 0.0719\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.8470 - accuracy: 0.0550\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7969 - accuracy: 0.0495\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7829 - accuracy: 0.0495\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.7831 - accuracy: 0.0496\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7781 - accuracy: 0.0495\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7739 - accuracy: 0.0495\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7727 - accuracy: 0.0497\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.7681 - accuracy: 0.0495\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.7661 - accuracy: 0.0498\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7578 - accuracy: 0.0496\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 1.7633 - accuracy: 0.0495\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7709 - accuracy: 0.0497\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7762 - accuracy: 0.0496\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7763 - accuracy: 0.0496\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7714 - accuracy: 0.0497\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7741 - accuracy: 0.0495\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7600 - accuracy: 0.0496\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7606 - accuracy: 0.0496\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7542 - accuracy: 0.0496\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7580 - accuracy: 0.0497\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7521 - accuracy: 0.0499\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7518 - accuracy: 0.0504\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7443 - accuracy: 0.0508\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7431 - accuracy: 0.0507\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7382 - accuracy: 0.0511\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7277 - accuracy: 0.0518\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7352 - accuracy: 0.0531\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7248 - accuracy: 0.0547\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7224 - accuracy: 0.0559\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7180 - accuracy: 0.0575\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7211 - accuracy: 0.0591\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7133 - accuracy: 0.0634\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.7089 - accuracy: 0.0682\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.6424 - accuracy: 0.0660\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.3986 - accuracy: 0.0469\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.3480 - accuracy: 0.0467\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3654 - accuracy: 0.0505\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3354 - accuracy: 0.0478\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.3323 - accuracy: 0.0486\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.3176 - accuracy: 0.0492\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3366 - accuracy: 0.0520\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3146 - accuracy: 0.0559\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 1.3378 - accuracy: 0.0616\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.3138 - accuracy: 0.0542\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.3065 - accuracy: 0.0582\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.3094 - accuracy: 0.0662\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2986 - accuracy: 0.0707\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2967 - accuracy: 0.0754\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.3310 - accuracy: 0.0688\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.3165 - accuracy: 0.0638\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2963 - accuracy: 0.0712\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2989 - accuracy: 0.0674\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2760 - accuracy: 0.0779\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.2750 - accuracy: 0.0896\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2526 - accuracy: 0.0808\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2617 - accuracy: 0.0947\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2903 - accuracy: 0.0944\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2470 - accuracy: 0.0748\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2465 - accuracy: 0.0731\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2470 - accuracy: 0.0860\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2696 - accuracy: 0.1002\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2672 - accuracy: 0.0963\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2704 - accuracy: 0.1015\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.2745 - accuracy: 0.1050\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2600 - accuracy: 0.1122\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2337 - accuracy: 0.1158\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2144 - accuracy: 0.1141\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2231 - accuracy: 0.1212\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2624 - accuracy: 0.1202\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2582 - accuracy: 0.1288\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2453 - accuracy: 0.0946\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2605 - accuracy: 0.0741\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2223 - accuracy: 0.0817\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2095 - accuracy: 0.1023\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1925 - accuracy: 0.1160\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.1878 - accuracy: 0.1212\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2629 - accuracy: 0.1275\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.2514 - accuracy: 0.1096\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2174 - accuracy: 0.1080\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9902 - accuracy: 0.0998\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9872 - accuracy: 0.0965\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0428 - accuracy: 0.0729\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9809 - accuracy: 0.0547\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9469 - accuracy: 0.0462\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9205 - accuracy: 0.0419\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9229 - accuracy: 0.0529\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9402 - accuracy: 0.0624\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9099 - accuracy: 0.0758\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9045 - accuracy: 0.0860\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9237 - accuracy: 0.0913\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9115 - accuracy: 0.0829\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9095 - accuracy: 0.0802\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8818 - accuracy: 0.0910\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8547 - accuracy: 0.0979\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8625 - accuracy: 0.1155\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8886 - accuracy: 0.1322\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8750 - accuracy: 0.1299\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8826 - accuracy: 0.1248\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8872 - accuracy: 0.1100\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8884 - accuracy: 0.0945\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9106 - accuracy: 0.0902\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8688 - accuracy: 0.1001\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8948 - accuracy: 0.1106\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8740 - accuracy: 0.1145\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8867 - accuracy: 0.1337\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8788 - accuracy: 0.1260\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8957 - accuracy: 0.1213\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9617 - accuracy: 0.0956\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9306 - accuracy: 0.0901\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9028 - accuracy: 0.1003\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8604 - accuracy: 0.1078\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8566 - accuracy: 0.1200\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8322 - accuracy: 0.1103\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8752 - accuracy: 0.1081\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8323 - accuracy: 0.1087\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8536 - accuracy: 0.0952\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8395 - accuracy: 0.1117\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8306 - accuracy: 0.1178\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8318 - accuracy: 0.1197\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8993 - accuracy: 0.1087\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0770 - accuracy: 0.0828\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0075 - accuracy: 0.0539\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0174 - accuracy: 0.0477\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9829 - accuracy: 0.0417\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9644 - accuracy: 0.0370\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9323 - accuracy: 0.0437\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9194 - accuracy: 0.0530\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9040 - accuracy: 0.0625\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9117 - accuracy: 0.0582\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9269 - accuracy: 0.0565\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9119 - accuracy: 0.0578\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9101 - accuracy: 0.0625\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9102 - accuracy: 0.0678\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8828 - accuracy: 0.0689\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9065 - accuracy: 0.0730\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8794 - accuracy: 0.0890\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8922 - accuracy: 0.0924\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8385 - accuracy: 0.0958\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8746 - accuracy: 0.0929\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8545 - accuracy: 0.0875\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8852 - accuracy: 0.0877\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8995 - accuracy: 0.0940\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8749 - accuracy: 0.0957\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9691 - accuracy: 0.0552\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0076 - accuracy: 0.0279\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0014 - accuracy: 0.0189\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9830 - accuracy: 0.0197\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9629 - accuracy: 0.0192\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9643 - accuracy: 0.0209\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9323 - accuracy: 0.0241\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9632 - accuracy: 0.0274\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9623 - accuracy: 0.0315\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9250 - accuracy: 0.0345\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9116 - accuracy: 0.0410\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9085 - accuracy: 0.0473\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9177 - accuracy: 0.0555\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9103 - accuracy: 0.0566\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9004 - accuracy: 0.0630\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8905 - accuracy: 0.0714\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9073 - accuracy: 0.0796\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8797 - accuracy: 0.0905\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8930 - accuracy: 0.0946\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8946 - accuracy: 0.0911\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8664 - accuracy: 0.0913\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8670 - accuracy: 0.0880\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8791 - accuracy: 0.0688\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8950 - accuracy: 0.0639\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8755 - accuracy: 0.0679\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8923 - accuracy: 0.0830\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8916 - accuracy: 0.0810\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8825 - accuracy: 0.0753\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8850 - accuracy: 0.0861\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8588 - accuracy: 0.0925\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8910 - accuracy: 0.0944\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9154 - accuracy: 0.0725\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9188 - accuracy: 0.0648\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8838 - accuracy: 0.0667\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8615 - accuracy: 0.0666\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8576 - accuracy: 0.0782\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8803 - accuracy: 0.0875\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8465 - accuracy: 0.0941\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8460 - accuracy: 0.0948\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8521 - accuracy: 0.0969\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8628 - accuracy: 0.1058\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8121 - accuracy: 0.1025\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8436 - accuracy: 0.1021\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8276 - accuracy: 0.1091\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8368 - accuracy: 0.0987\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8452 - accuracy: 0.1026\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8475 - accuracy: 0.1105\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8261 - accuracy: 0.1251\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8322 - accuracy: 0.1295\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8572 - accuracy: 0.1330\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8186 - accuracy: 0.1364\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8376 - accuracy: 0.1477\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8575 - accuracy: 0.1546\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8079 - accuracy: 0.1416\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8525 - accuracy: 0.1399\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8025 - accuracy: 0.1416\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7979 - accuracy: 0.1364\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8132 - accuracy: 0.1271\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8432 - accuracy: 0.1318\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8799 - accuracy: 0.1327\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9597 - accuracy: 0.0868\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9607 - accuracy: 0.0772\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9023 - accuracy: 0.0677\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9034 - accuracy: 0.0738\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8919 - accuracy: 0.0804\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8869 - accuracy: 0.0941\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8543 - accuracy: 0.1010\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8479 - accuracy: 0.1059\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8152 - accuracy: 0.1195\n",
      "Epoch 222/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8987 - accuracy: 0.1308\n",
      "Epoch 223/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8357 - accuracy: 0.1102\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8420 - accuracy: 0.1077\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8203 - accuracy: 0.1183\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8499 - accuracy: 0.1193\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8485 - accuracy: 0.1157\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8420 - accuracy: 0.1001\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0766 - accuracy: 0.0641\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.0066 - accuracy: 0.0409\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9713 - accuracy: 0.0289\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9749 - accuracy: 0.0308\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.9618 - accuracy: 0.0351\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9348 - accuracy: 0.0379\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9359 - accuracy: 0.0355\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9489 - accuracy: 0.0383\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9477 - accuracy: 0.0439\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.9191 - accuracy: 0.0453\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9296 - accuracy: 0.0427\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9314 - accuracy: 0.0447\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9143 - accuracy: 0.0530\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8986 - accuracy: 0.0614\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8982 - accuracy: 0.0664\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8787 - accuracy: 0.0711\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8872 - accuracy: 0.0707\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8839 - accuracy: 0.0735\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8778 - accuracy: 0.0799\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8800 - accuracy: 0.0780\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9086 - accuracy: 0.0804\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8947 - accuracy: 0.0773\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8805 - accuracy: 0.0662\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8846 - accuracy: 0.0651\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8892 - accuracy: 0.0669\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8859 - accuracy: 0.0793\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8594 - accuracy: 0.0876\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8380 - accuracy: 0.0970\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8482 - accuracy: 0.0959\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8522 - accuracy: 0.0999\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8371 - accuracy: 0.1089\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8334 - accuracy: 0.1152\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8223 - accuracy: 0.1094\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8341 - accuracy: 0.1138\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8700 - accuracy: 0.1143\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8566 - accuracy: 0.1145\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8552 - accuracy: 0.1190\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.8573 - accuracy: 0.1089\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8329 - accuracy: 0.1197\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8124 - accuracy: 0.1315\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8092 - accuracy: 0.1272\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8188 - accuracy: 0.1345\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7962 - accuracy: 0.1447\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7881 - accuracy: 0.1444\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8416 - accuracy: 0.1218\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8853 - accuracy: 0.0944\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8619 - accuracy: 0.0909\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8333 - accuracy: 0.1001\n",
      "Epoch 277/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8315 - accuracy: 0.1094\n",
      "Epoch 278/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8200 - accuracy: 0.1148\n",
      "Epoch 279/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8418 - accuracy: 0.1201\n",
      "Epoch 280/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8268 - accuracy: 0.1304\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.8404 - accuracy: 0.1139\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8389 - accuracy: 0.1016\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8723 - accuracy: 0.0877\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8822 - accuracy: 0.0823\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8622 - accuracy: 0.0818\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8753 - accuracy: 0.0789\n",
      "Epoch 287/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8862 - accuracy: 0.0800\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8647 - accuracy: 0.0831\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8685 - accuracy: 0.0893\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8662 - accuracy: 0.0980\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8502 - accuracy: 0.0975\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.8484 - accuracy: 0.1010\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.8330 - accuracy: 0.1088\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8652 - accuracy: 0.1075\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8557 - accuracy: 0.0989\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8333 - accuracy: 0.1023\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8258 - accuracy: 0.1069\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8085 - accuracy: 0.1161\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8115 - accuracy: 0.1184\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8160 - accuracy: 0.1250\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8279 - accuracy: 0.1096\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8796 - accuracy: 0.1098\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8301 - accuracy: 0.1118\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8265 - accuracy: 0.1168\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8095 - accuracy: 0.1231\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8037 - accuracy: 0.1227\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8266 - accuracy: 0.0967\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8329 - accuracy: 0.0978\n",
      "Epoch 309/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8356 - accuracy: 0.1139\n",
      "Epoch 310/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8560 - accuracy: 0.1304\n",
      "Epoch 311/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8647 - accuracy: 0.1261\n",
      "Epoch 312/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8140 - accuracy: 0.1225\n",
      "Epoch 313/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7932 - accuracy: 0.1316\n",
      "Epoch 314/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7874 - accuracy: 0.1247\n",
      "Epoch 315/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7925 - accuracy: 0.1355\n",
      "Epoch 316/1000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.7765 - accuracy: 0.1354\n",
      "Epoch 317/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8173 - accuracy: 0.1334\n",
      "Epoch 318/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8320 - accuracy: 0.1277\n",
      "Epoch 319/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.7996 - accuracy: 0.1378\n",
      "Epoch 320/1000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.7453 - accuracy: 0.1451\n",
      "Epoch 321/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7576 - accuracy: 0.1515\n",
      "Epoch 322/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7560 - accuracy: 0.1595\n",
      "Epoch 323/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7953 - accuracy: 0.1704\n",
      "Epoch 324/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7368 - accuracy: 0.1646\n",
      "Epoch 325/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7658 - accuracy: 0.1666\n",
      "Epoch 326/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7646 - accuracy: 0.1738\n",
      "Epoch 327/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7516 - accuracy: 0.1906\n",
      "Epoch 328/1000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.7334 - accuracy: 0.1632\n",
      "Epoch 329/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7475 - accuracy: 0.1545\n",
      "Epoch 330/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7584 - accuracy: 0.1482\n",
      "Epoch 331/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7472 - accuracy: 0.1661\n",
      "Epoch 332/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7383 - accuracy: 0.1874\n",
      "Epoch 333/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8217 - accuracy: 0.1917\n",
      "Epoch 334/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7683 - accuracy: 0.1822\n",
      "Epoch 335/1000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.7592 - accuracy: 0.1617\n",
      "Epoch 336/1000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.7371 - accuracy: 0.1595\n",
      "Epoch 337/1000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.7323 - accuracy: 0.1647\n",
      "Epoch 338/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.7257 - accuracy: 0.1704\n",
      "Epoch 339/1000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.7319 - accuracy: 0.1752\n",
      "Epoch 340/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7886 - accuracy: 0.1664\n",
      "Epoch 341/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8011 - accuracy: 0.1539\n",
      "Epoch 342/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8178 - accuracy: 0.1526\n",
      "Epoch 343/1000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.7998 - accuracy: 0.1410\n",
      "Epoch 344/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.9003 - accuracy: 0.1193\n",
      "Epoch 345/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8755 - accuracy: 0.1003\n",
      "Epoch 346/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8924 - accuracy: 0.0929\n",
      "Epoch 347/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8951 - accuracy: 0.0894\n",
      "Epoch 348/1000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.8491 - accuracy: 0.0998\n",
      "Epoch 349/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8592 - accuracy: 0.1032\n",
      "Epoch 350/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8440 - accuracy: 0.1143\n",
      "Epoch 351/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8506 - accuracy: 0.1125\n",
      "Epoch 352/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8438 - accuracy: 0.1243\n",
      "Epoch 353/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8340 - accuracy: 0.1366\n",
      "Epoch 354/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8447 - accuracy: 0.1519\n",
      "Epoch 355/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8252 - accuracy: 0.1519\n",
      "Epoch 356/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8357 - accuracy: 0.1281\n",
      "Epoch 357/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8895 - accuracy: 0.1014\n",
      "Epoch 358/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9275 - accuracy: 0.0935\n",
      "Epoch 359/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8963 - accuracy: 0.0980\n",
      "Epoch 360/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.9005 - accuracy: 0.1081\n",
      "Epoch 361/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8578 - accuracy: 0.1190\n",
      "Epoch 362/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8408 - accuracy: 0.1173\n",
      "Epoch 363/1000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.8459 - accuracy: 0.1116\n",
      "Epoch 364/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8227 - accuracy: 0.1057\n",
      "Epoch 365/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8208 - accuracy: 0.1147\n",
      "Epoch 366/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8361 - accuracy: 0.1158\n",
      "Epoch 367/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8187 - accuracy: 0.1205\n",
      "Epoch 368/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8380 - accuracy: 0.1282\n",
      "Epoch 369/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8233 - accuracy: 0.1388\n",
      "Epoch 370/1000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.8983 - accuracy: 0.1300\n",
      "Epoch 371/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8736 - accuracy: 0.1209\n",
      "Epoch 372/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8530 - accuracy: 0.1168\n",
      "Epoch 373/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8164 - accuracy: 0.1228\n",
      "Epoch 374/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8162 - accuracy: 0.1313\n",
      "Epoch 375/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8437 - accuracy: 0.1313\n",
      "Epoch 376/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8284 - accuracy: 0.1297\n",
      "Epoch 377/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8244 - accuracy: 0.1232\n",
      "Epoch 378/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8312 - accuracy: 0.1181\n",
      "Epoch 379/1000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.7910 - accuracy: 0.1220\n",
      "Epoch 380/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8010 - accuracy: 0.1190\n",
      "Epoch 381/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8407 - accuracy: 0.1120\n",
      "Epoch 382/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8322 - accuracy: 0.1163\n",
      "Epoch 383/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8021 - accuracy: 0.1190\n",
      "Epoch 384/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8403 - accuracy: 0.1200\n",
      "Epoch 385/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8209 - accuracy: 0.1367\n",
      "Epoch 386/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7860 - accuracy: 0.1383\n",
      "Epoch 387/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7971 - accuracy: 0.1520\n",
      "Epoch 388/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8284 - accuracy: 0.1316\n",
      "Epoch 389/1000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.9034 - accuracy: 0.0821\n",
      "Epoch 390/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8864 - accuracy: 0.0639\n",
      "Epoch 391/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8744 - accuracy: 0.0554\n",
      "Epoch 392/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8837 - accuracy: 0.0568\n",
      "Epoch 393/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8490 - accuracy: 0.0655\n",
      "Epoch 394/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8354 - accuracy: 0.0785\n",
      "Epoch 395/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8434 - accuracy: 0.0868\n",
      "Epoch 396/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8506 - accuracy: 0.0911\n",
      "Epoch 397/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8146 - accuracy: 0.1041\n",
      "Epoch 398/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8388 - accuracy: 0.1205\n",
      "Epoch 399/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8306 - accuracy: 0.1249\n",
      "Epoch 400/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8291 - accuracy: 0.1275\n",
      "Epoch 401/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7789 - accuracy: 0.1150\n",
      "Epoch 402/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8434 - accuracy: 0.1082\n",
      "Epoch 403/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8343 - accuracy: 0.1218\n",
      "Epoch 404/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8091 - accuracy: 0.1156\n",
      "Epoch 405/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8298 - accuracy: 0.1059\n",
      "Epoch 406/1000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.8242 - accuracy: 0.1113\n",
      "Epoch 407/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8365 - accuracy: 0.1095\n",
      "Epoch 408/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8063 - accuracy: 0.1068\n",
      "Epoch 409/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8050 - accuracy: 0.1081\n",
      "Epoch 410/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8171 - accuracy: 0.1212\n",
      "Epoch 411/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8169 - accuracy: 0.1162\n",
      "Epoch 412/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7850 - accuracy: 0.1217\n",
      "Epoch 413/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.7664 - accuracy: 0.1303\n",
      "Epoch 414/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7658 - accuracy: 0.1416\n",
      "Epoch 415/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7870 - accuracy: 0.1321\n",
      "Epoch 416/1000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.7999 - accuracy: 0.1213\n",
      "Epoch 417/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8023 - accuracy: 0.1147\n",
      "Epoch 418/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8044 - accuracy: 0.1080\n",
      "Epoch 419/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8194 - accuracy: 0.1154\n",
      "Epoch 420/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7800 - accuracy: 0.1230\n",
      "Epoch 421/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7882 - accuracy: 0.1255\n",
      "Epoch 422/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7995 - accuracy: 0.1208\n",
      "Epoch 423/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7966 - accuracy: 0.1224\n",
      "Epoch 424/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8206 - accuracy: 0.1239\n",
      "Epoch 425/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.9344 - accuracy: 0.0936\n",
      "Epoch 426/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9708 - accuracy: 0.0883\n",
      "Epoch 427/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.9360 - accuracy: 0.0716\n",
      "Epoch 428/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.9043 - accuracy: 0.0595\n",
      "Epoch 429/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.9074 - accuracy: 0.0587\n",
      "Epoch 430/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8771 - accuracy: 0.0682\n",
      "Epoch 431/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8577 - accuracy: 0.0712\n",
      "Epoch 432/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8584 - accuracy: 0.0815\n",
      "Epoch 433/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8579 - accuracy: 0.0816\n",
      "Epoch 434/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8453 - accuracy: 0.0899\n",
      "Epoch 435/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8534 - accuracy: 0.0963\n",
      "Epoch 436/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8485 - accuracy: 0.0991\n",
      "Epoch 437/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8462 - accuracy: 0.0991\n",
      "Epoch 438/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8377 - accuracy: 0.1107\n",
      "Epoch 439/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8448 - accuracy: 0.1194\n",
      "Epoch 440/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8266 - accuracy: 0.1156\n",
      "Epoch 441/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8481 - accuracy: 0.1190\n",
      "Epoch 442/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7917 - accuracy: 0.1277\n",
      "Epoch 443/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8126 - accuracy: 0.1329\n",
      "Epoch 444/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8063 - accuracy: 0.1343\n",
      "Epoch 445/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7988 - accuracy: 0.1243\n",
      "Epoch 446/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8068 - accuracy: 0.1274\n",
      "Epoch 447/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7730 - accuracy: 0.1325\n",
      "Epoch 448/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb Cella 20\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     [\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         k\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLSTM(\u001b[39m30\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(\u001b[39m0.001\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mAccuracy()]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_prova, y_prova, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/keras/engine/training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/keras/callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \n\u001b[1;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/keras/callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/keras/callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/keras/callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[1;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/keras/callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/keras/callbacks.py:1158\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m-> 1158\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprogbar\u001b[39m.\u001b[39;49mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseen, \u001b[39mlist\u001b[39;49m(logs\u001b[39m.\u001b[39;49mitems()), finalize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/keras/utils/generic_utils.py:1037\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m   1033\u001b[0m avg \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(\n\u001b[1;32m   1034\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[k][\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[k][\u001b[39m1\u001b[39m])\n\u001b[1;32m   1035\u001b[0m )\n\u001b[1;32m   1036\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mabs\u001b[39m(avg) \u001b[39m>\u001b[39m \u001b[39m1e-3\u001b[39m:\n\u001b[0;32m-> 1037\u001b[0m     info \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m%.4f\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m avg\n\u001b[1;32m   1038\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1039\u001b[0m     info \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m%.4e\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m avg\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 65-67% Accuracy no Overfit\n",
    "model = k.models.Sequential(\n",
    "    [\n",
    "        k.layers.LSTM(30),\n",
    "        k.layers.Dense(1000, activation=\"relu\"),\n",
    "        k.layers.Dropout(0.4),\n",
    "        k.layers.Dense(250, activation=\"relu\"),\n",
    "        k.layers.Dropout(0.2),\n",
    "        k.layers.Dense(30, activation=\"relu\"),\n",
    "        k.layers.Reshape((10, 3)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=[tf.keras.metrics.Accuracy()]\n",
    ")\n",
    "\n",
    "model.fit(x_prova, y_prova, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 12:59:42.539701: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-05 12:59:42.613182: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 41ms/step - loss: 2.2390 - accuracy: 0.0734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2390284538269043, 0.07339181005954742]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_prova_test, y_prova_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 10, 94)\n",
      "1/4 [======>.......................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 12:59:44.341371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-05 12:59:44.399684: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 24ms/step\n",
      "[[[1.0756292  0.         1.6736791 ]\n",
      "  [2.6071496  0.         3.9934971 ]\n",
      "  [0.         3.5384612  0.        ]\n",
      "  ...\n",
      "  [0.         0.         2.1049345 ]\n",
      "  [0.         2.8374145  0.        ]\n",
      "  [0.4417551  0.9153567  0.7121923 ]]\n",
      "\n",
      " [[2.1978781  1.6746589  3.578195  ]\n",
      "  [0.8946435  2.544868   5.1717315 ]\n",
      "  [3.9018521  4.870901   4.477558  ]\n",
      "  ...\n",
      "  [2.9291863  3.654651   2.9990366 ]\n",
      "  [2.2434068  4.6095796  3.3329449 ]\n",
      "  [2.2950897  0.9802348  7.892979  ]]\n",
      "\n",
      " [[3.3220043  2.2513387  5.4257765 ]\n",
      "  [5.5586476  3.5043566  6.027802  ]\n",
      "  [2.2562926  5.2247515  4.6893115 ]\n",
      "  ...\n",
      "  [2.9763765  2.457679   4.2613654 ]\n",
      "  [1.3316855  3.2381716  6.7113905 ]\n",
      "  [4.5631447  4.075909   3.0562885 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         1.8861023  2.3555148 ]\n",
      "  [1.3947667  2.0156822  6.7626586 ]\n",
      "  [3.2876775  0.21468496 1.7362942 ]\n",
      "  ...\n",
      "  [0.64773494 3.5973024  2.7812085 ]\n",
      "  [5.0609574  1.7696464  0.47302046]\n",
      "  [0.7726325  0.         6.485748  ]]\n",
      "\n",
      " [[2.190314   3.2683988  2.021895  ]\n",
      "  [1.789462   3.900584   4.0114694 ]\n",
      "  [2.2623467  4.0249996  4.1438346 ]\n",
      "  ...\n",
      "  [1.5679294  1.3703455  3.4156253 ]\n",
      "  [1.308119   0.68987906 4.6636157 ]\n",
      "  [6.0673175  0.         3.734506  ]]\n",
      "\n",
      " [[3.2229238  1.9937787  4.8487    ]\n",
      "  [5.8171554  3.3237958  6.2608547 ]\n",
      "  [2.536062   4.098077   4.3927274 ]\n",
      "  ...\n",
      "  [3.2498372  1.9573721  4.2022266 ]\n",
      "  [1.6348897  1.84497    6.6658087 ]\n",
      "  [4.3260775  3.2025135  2.753214  ]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_prova_test.shape)\n",
    "result = model.predict(x_prova_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A      0.310     0.249     0.277       345\n",
      "           D      0.185     0.110     0.138       254\n",
      "           H      0.479     0.630     0.544       541\n",
      "\n",
      "    accuracy                          0.399      1140\n",
      "   macro avg      0.325     0.330     0.320      1140\n",
      "weighted avg      0.363     0.399     0.373      1140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def revert_yoh(Y):\n",
    "    Y_new = np.empty([Y.shape[0],Y.shape[1]], dtype=\"<U1\")\n",
    "    #Y_new = np.zeros((Y.shape[0],Y.shape[1]))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if (Y[i, j] == 0):\n",
    "                Y_new[i, j]= 'A'\n",
    "            elif (Y[i, j] == 1):\n",
    "                Y_new[i, j]= 'D'\n",
    "            elif (Y[i, j] == 2):\n",
    "                Y_new[i, j]='H'\n",
    "    return Y_new\n",
    "\n",
    "y_pred = model.predict(x_prova_test)\n",
    "y_predm = np.asarray(y_pred)\n",
    "y_predm = np.argmax(y_predm, axis=2)\n",
    "y_testm = np.argmax(y_prova_test, axis=2)\n",
    "\n",
    "y_pred_train = model.predict(x_prova)\n",
    "y_pred_train = np.asarray(y_pred_train)\n",
    "y_predm_train = np.argmax(y_pred_train, axis=2)\n",
    "y_trainm = np.argmax(y_prova, axis = 2)\n",
    "\n",
    "y_predm = revert_yoh(y_predm).ravel()\n",
    "y_testm = revert_yoh(y_testm).ravel()\n",
    "\n",
    "y_predm_train = revert_yoh(y_predm_train).ravel()\n",
    "y_trainm = revert_yoh(y_trainm).ravel()\n",
    "\n",
    "#Model Metrics\n",
    "print(classification_report(y_testm, y_predm, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# trasforma i valori delle vittorie come 2 e dei pareggi come 1\n",
    "y_nn = (data[['ordinalHR']].to_numpy().ravel()*2).reshape(-1,1)\n",
    "\n",
    "y_nn = OneHotEncoder(sparse=False).fit_transform(y_nn)\n",
    "print(y_nn)\n",
    "#Split X and Y into training and Test Sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_imputed, y_nn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = k.models.Sequential([\n",
    "    k.layers.Dense(300, activation='relu'),\n",
    "    k.layers.Dense(100, activation='relu'),\n",
    "    k.layers.Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (3135, 300)               28500     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (3135, 100)               30100     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (3135, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,903\n",
      "Trainable params: 58,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.001\n",
    "\n",
    "nn.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=k.optimizers.Adam(learning_rate),\n",
    "    metrics=[k.metrics.Accuracy()]\n",
    ")\n",
    "nn(x_train)\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.8017 - accuracy: 1.0633e-04\n",
      "Epoch 2/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7883 - accuracy: 2.1265e-04\n",
      "Epoch 3/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7957 - accuracy: 2.1265e-04\n",
      "Epoch 4/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7899 - accuracy: 2.1265e-04\n",
      "Epoch 5/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7861 - accuracy: 2.1265e-04\n",
      "Epoch 6/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7771 - accuracy: 2.1265e-04\n",
      "Epoch 7/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7812 - accuracy: 2.1265e-04\n",
      "Epoch 8/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7840 - accuracy: 2.1265e-04\n",
      "Epoch 9/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7735 - accuracy: 1.0633e-04\n",
      "Epoch 10/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7750 - accuracy: 2.1265e-04\n",
      "Epoch 11/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7711 - accuracy: 1.0633e-04\n",
      "Epoch 12/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7696 - accuracy: 2.1265e-04\n",
      "Epoch 13/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7616 - accuracy: 2.1265e-04\n",
      "Epoch 14/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7616 - accuracy: 2.1265e-04\n",
      "Epoch 15/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7607 - accuracy: 1.0633e-04\n",
      "Epoch 16/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7718 - accuracy: 2.1265e-04\n",
      "Epoch 17/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7572 - accuracy: 0.0000e+00\n",
      "Epoch 18/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7468 - accuracy: 2.1265e-04\n",
      "Epoch 19/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7384 - accuracy: 2.1265e-04\n",
      "Epoch 20/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7306 - accuracy: 2.1265e-04\n",
      "Epoch 21/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7392 - accuracy: 2.1265e-04\n",
      "Epoch 22/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7267 - accuracy: 4.2531e-04\n",
      "Epoch 23/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7331 - accuracy: 5.3163e-04\n",
      "Epoch 24/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7188 - accuracy: 2.1265e-04\n",
      "Epoch 25/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7217 - accuracy: 3.1898e-04\n",
      "Epoch 26/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7147 - accuracy: 2.1265e-04\n",
      "Epoch 27/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7080 - accuracy: 2.1265e-04\n",
      "Epoch 28/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7234 - accuracy: 2.1265e-04\n",
      "Epoch 29/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7196 - accuracy: 3.1898e-04\n",
      "Epoch 30/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7177 - accuracy: 2.1265e-04\n",
      "Epoch 31/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7071 - accuracy: 1.0633e-04\n",
      "Epoch 32/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6995 - accuracy: 4.2531e-04\n",
      "Epoch 33/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6964 - accuracy: 2.1265e-04\n",
      "Epoch 34/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6896 - accuracy: 3.1898e-04\n",
      "Epoch 35/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6873 - accuracy: 3.1898e-04\n",
      "Epoch 36/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6988 - accuracy: 1.0633e-04\n",
      "Epoch 37/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6745 - accuracy: 3.1898e-04\n",
      "Epoch 38/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6724 - accuracy: 2.1265e-04\n",
      "Epoch 39/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6737 - accuracy: 3.1898e-04\n",
      "Epoch 40/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6710 - accuracy: 4.2531e-04\n",
      "Epoch 41/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6640 - accuracy: 5.3163e-04\n",
      "Epoch 42/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6604 - accuracy: 4.2531e-04\n",
      "Epoch 43/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6450 - accuracy: 3.1898e-04\n",
      "Epoch 44/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6464 - accuracy: 3.1898e-04\n",
      "Epoch 45/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6542 - accuracy: 2.1265e-04\n",
      "Epoch 46/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6391 - accuracy: 3.1898e-04\n",
      "Epoch 47/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6311 - accuracy: 4.2531e-04\n",
      "Epoch 48/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6333 - accuracy: 4.2531e-04\n",
      "Epoch 49/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6387 - accuracy: 4.2531e-04\n",
      "Epoch 50/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6238 - accuracy: 5.3163e-04\n",
      "Epoch 51/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6207 - accuracy: 5.3163e-04\n",
      "Epoch 52/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6197 - accuracy: 4.2531e-04\n",
      "Epoch 53/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6074 - accuracy: 3.1898e-04\n",
      "Epoch 54/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6174 - accuracy: 2.1265e-04\n",
      "Epoch 55/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6138 - accuracy: 4.2531e-04\n",
      "Epoch 56/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6068 - accuracy: 4.2531e-04\n",
      "Epoch 57/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6115 - accuracy: 4.2531e-04\n",
      "Epoch 58/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5933 - accuracy: 2.1265e-04\n",
      "Epoch 59/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5912 - accuracy: 3.1898e-04\n",
      "Epoch 60/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5823 - accuracy: 6.3796e-04\n",
      "Epoch 61/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5909 - accuracy: 6.3796e-04\n",
      "Epoch 62/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5743 - accuracy: 6.3796e-04\n",
      "Epoch 63/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5841 - accuracy: 4.2531e-04\n",
      "Epoch 64/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5674 - accuracy: 7.4428e-04\n",
      "Epoch 65/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5856 - accuracy: 5.3163e-04\n",
      "Epoch 66/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5792 - accuracy: 4.2531e-04\n",
      "Epoch 67/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5648 - accuracy: 7.4428e-04\n",
      "Epoch 68/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5707 - accuracy: 9.5694e-04\n",
      "Epoch 69/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5566 - accuracy: 8.5061e-04\n",
      "Epoch 70/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5458 - accuracy: 5.3163e-04\n",
      "Epoch 71/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5433 - accuracy: 7.4428e-04\n",
      "Epoch 72/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5375 - accuracy: 5.3163e-04\n",
      "Epoch 73/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5360 - accuracy: 0.0011\n",
      "Epoch 74/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5334 - accuracy: 8.5061e-04\n",
      "Epoch 75/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5224 - accuracy: 0.0012\n",
      "Epoch 76/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5206 - accuracy: 0.0011\n",
      "Epoch 77/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5187 - accuracy: 8.5061e-04\n",
      "Epoch 78/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5121 - accuracy: 9.5694e-04\n",
      "Epoch 79/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5050 - accuracy: 0.0014\n",
      "Epoch 80/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5057 - accuracy: 0.0014\n",
      "Epoch 81/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5215 - accuracy: 0.0013\n",
      "Epoch 82/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5113 - accuracy: 0.0011\n",
      "Epoch 83/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4928 - accuracy: 0.0017\n",
      "Epoch 84/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5046 - accuracy: 0.0013\n",
      "Epoch 85/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.4945 - accuracy: 0.0014\n",
      "Epoch 86/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4932 - accuracy: 0.0013\n",
      "Epoch 87/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4738 - accuracy: 0.0015\n",
      "Epoch 88/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4878 - accuracy: 0.0015\n",
      "Epoch 89/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4751 - accuracy: 0.0014\n",
      "Epoch 90/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4711 - accuracy: 0.0016\n",
      "Epoch 91/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4392 - accuracy: 0.0018\n",
      "Epoch 92/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4615 - accuracy: 0.0016\n",
      "Epoch 93/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4505 - accuracy: 0.0020\n",
      "Epoch 94/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.4648 - accuracy: 0.0018\n",
      "Epoch 95/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4487 - accuracy: 0.0018\n",
      "Epoch 96/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4478 - accuracy: 0.0020\n",
      "Epoch 97/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.4319 - accuracy: 0.0018\n",
      "Epoch 98/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4469 - accuracy: 0.0022\n",
      "Epoch 99/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4554 - accuracy: 0.0021\n",
      "Epoch 100/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.4401 - accuracy: 0.0019\n",
      "Epoch 101/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.4476 - accuracy: 0.0019\n",
      "Epoch 102/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4277 - accuracy: 0.0014\n",
      "Epoch 103/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.4553 - accuracy: 0.0019\n",
      "Epoch 104/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4157 - accuracy: 0.0021\n",
      "Epoch 105/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3934 - accuracy: 0.0018\n",
      "Epoch 106/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3818 - accuracy: 0.0019\n",
      "Epoch 107/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3850 - accuracy: 0.0022\n",
      "Epoch 108/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4086 - accuracy: 0.0029\n",
      "Epoch 109/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3861 - accuracy: 0.0036\n",
      "Epoch 110/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3690 - accuracy: 0.0027\n",
      "Epoch 111/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3908 - accuracy: 0.0030\n",
      "Epoch 112/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3846 - accuracy: 0.0030\n",
      "Epoch 113/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.4005 - accuracy: 0.0026\n",
      "Epoch 114/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3778 - accuracy: 0.0032\n",
      "Epoch 115/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3631 - accuracy: 0.0030\n",
      "Epoch 116/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3569 - accuracy: 0.0031\n",
      "Epoch 117/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3632 - accuracy: 0.0036\n",
      "Epoch 118/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3709 - accuracy: 0.0032\n",
      "Epoch 119/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3610 - accuracy: 0.0037\n",
      "Epoch 120/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3433 - accuracy: 0.0040\n",
      "Epoch 121/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3842 - accuracy: 0.0034\n",
      "Epoch 122/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3736 - accuracy: 0.0033\n",
      "Epoch 123/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3296 - accuracy: 0.0038\n",
      "Epoch 124/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3251 - accuracy: 0.0041\n",
      "Epoch 125/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3522 - accuracy: 0.0043\n",
      "Epoch 126/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3401 - accuracy: 0.0044\n",
      "Epoch 127/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3255 - accuracy: 0.0039\n",
      "Epoch 128/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3370 - accuracy: 0.0049\n",
      "Epoch 129/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3122 - accuracy: 0.0050\n",
      "Epoch 130/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3282 - accuracy: 0.0040\n",
      "Epoch 131/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3211 - accuracy: 0.0046\n",
      "Epoch 132/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3469 - accuracy: 0.0039\n",
      "Epoch 133/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3218 - accuracy: 0.0047\n",
      "Epoch 134/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3142 - accuracy: 0.0048\n",
      "Epoch 135/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3169 - accuracy: 0.0040\n",
      "Epoch 136/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3212 - accuracy: 0.0061\n",
      "Epoch 137/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.2949 - accuracy: 0.0052\n",
      "Epoch 138/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3212 - accuracy: 0.0046\n",
      "Epoch 139/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3285 - accuracy: 0.0053\n",
      "Epoch 140/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3114 - accuracy: 0.0044\n",
      "Epoch 141/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.2812 - accuracy: 0.0056\n",
      "Epoch 142/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3190 - accuracy: 0.0045\n",
      "Epoch 143/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2878 - accuracy: 0.0049\n",
      "Epoch 144/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2684 - accuracy: 0.0054\n",
      "Epoch 145/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2605 - accuracy: 0.0061\n",
      "Epoch 146/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2801 - accuracy: 0.0053\n",
      "Epoch 147/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3021 - accuracy: 0.0058\n",
      "Epoch 148/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2845 - accuracy: 0.0065\n",
      "Epoch 149/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3034 - accuracy: 0.0060\n",
      "Epoch 150/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3082 - accuracy: 0.0058\n",
      "Epoch 151/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2592 - accuracy: 0.0068\n",
      "Epoch 152/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2726 - accuracy: 0.0080\n",
      "Epoch 153/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2753 - accuracy: 0.0082\n",
      "Epoch 154/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2569 - accuracy: 0.0064\n",
      "Epoch 155/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2489 - accuracy: 0.0085\n",
      "Epoch 156/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2393 - accuracy: 0.0068\n",
      "Epoch 157/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2317 - accuracy: 0.0065\n",
      "Epoch 158/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2403 - accuracy: 0.0075\n",
      "Epoch 159/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2515 - accuracy: 0.0083\n",
      "Epoch 160/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2564 - accuracy: 0.0073\n",
      "Epoch 161/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2295 - accuracy: 0.0074\n",
      "Epoch 162/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2253 - accuracy: 0.0077\n",
      "Epoch 163/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2122 - accuracy: 0.0079\n",
      "Epoch 164/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2208 - accuracy: 0.0072\n",
      "Epoch 165/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2148 - accuracy: 0.0080\n",
      "Epoch 166/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2364 - accuracy: 0.0095\n",
      "Epoch 167/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2330 - accuracy: 0.0091\n",
      "Epoch 168/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2345 - accuracy: 0.0089\n",
      "Epoch 169/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2297 - accuracy: 0.0089\n",
      "Epoch 170/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2425 - accuracy: 0.0075\n",
      "Epoch 171/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2227 - accuracy: 0.0083\n",
      "Epoch 172/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2000 - accuracy: 0.0090\n",
      "Epoch 173/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1937 - accuracy: 0.0094\n",
      "Epoch 174/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1962 - accuracy: 0.0103\n",
      "Epoch 175/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1985 - accuracy: 0.0110\n",
      "Epoch 176/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2175 - accuracy: 0.0098\n",
      "Epoch 177/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2056 - accuracy: 0.0104\n",
      "Epoch 178/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2174 - accuracy: 0.0103\n",
      "Epoch 179/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1821 - accuracy: 0.0110\n",
      "Epoch 180/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1768 - accuracy: 0.0111\n",
      "Epoch 181/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1961 - accuracy: 0.0107\n",
      "Epoch 182/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1786 - accuracy: 0.0098\n",
      "Epoch 183/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1899 - accuracy: 0.0110\n",
      "Epoch 184/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1644 - accuracy: 0.0102\n",
      "Epoch 185/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1749 - accuracy: 0.0113\n",
      "Epoch 186/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1850 - accuracy: 0.0124\n",
      "Epoch 187/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1815 - accuracy: 0.0120\n",
      "Epoch 188/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1698 - accuracy: 0.0127\n",
      "Epoch 189/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1757 - accuracy: 0.0136\n",
      "Epoch 190/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.2110 - accuracy: 0.0104\n",
      "Epoch 191/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.3833 - accuracy: 0.0118\n",
      "Epoch 192/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3199 - accuracy: 0.0084\n",
      "Epoch 193/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2459 - accuracy: 0.0110\n",
      "Epoch 194/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1971 - accuracy: 0.0106\n",
      "Epoch 195/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1745 - accuracy: 0.0103\n",
      "Epoch 196/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1624 - accuracy: 0.0107\n",
      "Epoch 197/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1653 - accuracy: 0.0115\n",
      "Epoch 198/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1458 - accuracy: 0.0125\n",
      "Epoch 199/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1492 - accuracy: 0.0122\n",
      "Epoch 200/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1428 - accuracy: 0.0134\n",
      "Epoch 201/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1646 - accuracy: 0.0121\n",
      "Epoch 202/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1432 - accuracy: 0.0127\n",
      "Epoch 203/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1905 - accuracy: 0.0130\n",
      "Epoch 204/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1568 - accuracy: 0.0119\n",
      "Epoch 205/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1463 - accuracy: 0.0120\n",
      "Epoch 206/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1655 - accuracy: 0.0122\n",
      "Epoch 207/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1466 - accuracy: 0.0120\n",
      "Epoch 208/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1397 - accuracy: 0.0125\n",
      "Epoch 209/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1188 - accuracy: 0.0140\n",
      "Epoch 210/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1273 - accuracy: 0.0137\n",
      "Epoch 211/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1235 - accuracy: 0.0149\n",
      "Epoch 212/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1149 - accuracy: 0.0133\n",
      "Epoch 213/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1472 - accuracy: 0.0150\n",
      "Epoch 214/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1377 - accuracy: 0.0159\n",
      "Epoch 215/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.2320 - accuracy: 0.0127\n",
      "Epoch 216/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.2386 - accuracy: 0.0131\n",
      "Epoch 217/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.2128 - accuracy: 0.0124\n",
      "Epoch 218/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1519 - accuracy: 0.0149\n",
      "Epoch 219/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1394 - accuracy: 0.0140\n",
      "Epoch 220/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1530 - accuracy: 0.0154\n",
      "Epoch 221/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1448 - accuracy: 0.0144\n",
      "Epoch 222/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1208 - accuracy: 0.0151\n",
      "Epoch 223/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1258 - accuracy: 0.0174\n",
      "Epoch 224/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1416 - accuracy: 0.0152\n",
      "Epoch 225/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1164 - accuracy: 0.0149\n",
      "Epoch 226/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1120 - accuracy: 0.0153\n",
      "Epoch 227/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1021 - accuracy: 0.0158\n",
      "Epoch 228/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1206 - accuracy: 0.0177\n",
      "Epoch 229/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1284 - accuracy: 0.0188\n",
      "Epoch 230/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1146 - accuracy: 0.0165\n",
      "Epoch 231/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1092 - accuracy: 0.0180\n",
      "Epoch 232/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1400 - accuracy: 0.0184\n",
      "Epoch 233/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1059 - accuracy: 0.0177\n",
      "Epoch 234/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1053 - accuracy: 0.0168\n",
      "Epoch 235/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1098 - accuracy: 0.0187\n",
      "Epoch 236/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1106 - accuracy: 0.0178\n",
      "Epoch 237/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1759 - accuracy: 0.0168\n",
      "Epoch 238/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.2119 - accuracy: 0.0151\n",
      "Epoch 239/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3458 - accuracy: 0.0149\n",
      "Epoch 240/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.2358 - accuracy: 0.0157\n",
      "Epoch 241/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1706 - accuracy: 0.0134\n",
      "Epoch 242/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1403 - accuracy: 0.0155\n",
      "Epoch 243/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1513 - accuracy: 0.0145\n",
      "Epoch 244/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0870 - accuracy: 0.0151\n",
      "Epoch 245/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.0800 - accuracy: 0.0167\n",
      "Epoch 246/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0880 - accuracy: 0.0170\n",
      "Epoch 247/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0971 - accuracy: 0.0188\n",
      "Epoch 248/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0979 - accuracy: 0.0174\n",
      "Epoch 249/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1042 - accuracy: 0.0185\n",
      "Epoch 250/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.0796 - accuracy: 0.0189\n",
      "Epoch 251/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1157 - accuracy: 0.0201\n",
      "Epoch 252/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1395 - accuracy: 0.0190\n",
      "Epoch 253/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1799 - accuracy: 0.0181\n",
      "Epoch 254/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1141 - accuracy: 0.0198\n",
      "Epoch 255/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1079 - accuracy: 0.0183\n",
      "Epoch 256/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0819 - accuracy: 0.0192\n",
      "Epoch 257/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0729 - accuracy: 0.0216\n",
      "Epoch 258/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0787 - accuracy: 0.0216\n",
      "Epoch 259/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1000 - accuracy: 0.0206\n",
      "Epoch 260/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0917 - accuracy: 0.0228\n",
      "Epoch 261/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.0897 - accuracy: 0.0213\n",
      "Epoch 262/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1503 - accuracy: 0.0230\n",
      "Epoch 263/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1615 - accuracy: 0.0213\n",
      "Epoch 264/3000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.1446 - accuracy: 0.0199\n",
      "Epoch 265/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1491 - accuracy: 0.0180\n",
      "Epoch 266/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1201 - accuracy: 0.0167\n",
      "Epoch 267/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0913 - accuracy: 0.0206\n",
      "Epoch 268/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0673 - accuracy: 0.0209\n",
      "Epoch 269/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0689 - accuracy: 0.0224\n",
      "Epoch 270/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0958 - accuracy: 0.0225\n",
      "Epoch 271/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1059 - accuracy: 0.0222\n",
      "Epoch 272/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1175 - accuracy: 0.0214\n",
      "Epoch 273/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1369 - accuracy: 0.0231\n",
      "Epoch 274/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.2465 - accuracy: 0.0229\n",
      "Epoch 275/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1464 - accuracy: 0.0205\n",
      "Epoch 276/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1238 - accuracy: 0.0189\n",
      "Epoch 277/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1511 - accuracy: 0.0209\n",
      "Epoch 278/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.0931 - accuracy: 0.0229\n",
      "Epoch 279/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1124 - accuracy: 0.0214\n",
      "Epoch 280/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.1196 - accuracy: 0.0212\n",
      "Epoch 281/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0984 - accuracy: 0.0242\n",
      "Epoch 282/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0760 - accuracy: 0.0236\n",
      "Epoch 283/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0569 - accuracy: 0.0236\n",
      "Epoch 284/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0655 - accuracy: 0.0236\n",
      "Epoch 285/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0741 - accuracy: 0.0239\n",
      "Epoch 286/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.0544 - accuracy: 0.0238\n",
      "Epoch 287/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0571 - accuracy: 0.0246\n",
      "Epoch 288/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.0571 - accuracy: 0.0251\n",
      "Epoch 289/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0710 - accuracy: 0.0279\n",
      "Epoch 290/3000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.0989 - accuracy: 0.0257\n",
      "Epoch 291/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1015 - accuracy: 0.0248\n",
      "Epoch 292/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1406 - accuracy: 0.0270\n",
      "Epoch 293/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1270 - accuracy: 0.0255\n",
      "Epoch 294/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1613 - accuracy: 0.0215\n",
      "Epoch 295/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1640 - accuracy: 0.0226\n",
      "Epoch 296/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1605 - accuracy: 0.0248\n",
      "Epoch 297/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1289 - accuracy: 0.0272\n",
      "Epoch 298/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1231 - accuracy: 0.0239\n",
      "Epoch 299/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0907 - accuracy: 0.0245\n",
      "Epoch 300/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0667 - accuracy: 0.0250\n",
      "Epoch 301/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0575 - accuracy: 0.0237\n",
      "Epoch 302/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0695 - accuracy: 0.0259\n",
      "Epoch 303/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0537 - accuracy: 0.0245\n",
      "Epoch 304/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0517 - accuracy: 0.0267\n",
      "Epoch 305/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0484 - accuracy: 0.0276\n",
      "Epoch 306/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0486 - accuracy: 0.0268\n",
      "Epoch 307/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0696 - accuracy: 0.0288\n",
      "Epoch 308/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0667 - accuracy: 0.0273\n",
      "Epoch 309/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0593 - accuracy: 0.0292\n",
      "Epoch 310/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0753 - accuracy: 0.0289\n",
      "Epoch 311/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1289 - accuracy: 0.0318\n",
      "Epoch 312/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1166 - accuracy: 0.0247\n",
      "Epoch 313/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1139 - accuracy: 0.0289\n",
      "Epoch 314/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1833 - accuracy: 0.0257\n",
      "Epoch 315/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.2129 - accuracy: 0.0246\n",
      "Epoch 316/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3345 - accuracy: 0.0222\n",
      "Epoch 317/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.2197 - accuracy: 0.0293\n",
      "Epoch 318/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1489 - accuracy: 0.0258\n",
      "Epoch 319/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0772 - accuracy: 0.0273\n",
      "Epoch 320/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0493 - accuracy: 0.0279\n",
      "Epoch 321/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0417 - accuracy: 0.0289\n",
      "Epoch 322/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0739 - accuracy: 0.0265\n",
      "Epoch 323/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0522 - accuracy: 0.0301\n",
      "Epoch 324/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0401 - accuracy: 0.0275\n",
      "Epoch 325/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0364 - accuracy: 0.0297\n",
      "Epoch 326/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0376 - accuracy: 0.0302\n",
      "Epoch 327/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0381 - accuracy: 0.0316\n",
      "Epoch 328/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0564 - accuracy: 0.0321\n",
      "Epoch 329/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0730 - accuracy: 0.0318\n",
      "Epoch 330/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0659 - accuracy: 0.0331\n",
      "Epoch 331/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0600 - accuracy: 0.0339\n",
      "Epoch 332/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0424 - accuracy: 0.0327\n",
      "Epoch 333/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0345 - accuracy: 0.0340\n",
      "Epoch 334/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0417 - accuracy: 0.0343\n",
      "Epoch 335/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0636 - accuracy: 0.0364\n",
      "Epoch 336/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0973 - accuracy: 0.0330\n",
      "Epoch 337/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.2322 - accuracy: 0.0286\n",
      "Epoch 338/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.2173 - accuracy: 0.0268\n",
      "Epoch 339/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1305 - accuracy: 0.0300\n",
      "Epoch 340/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0877 - accuracy: 0.0324\n",
      "Epoch 341/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0596 - accuracy: 0.0301\n",
      "Epoch 342/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0440 - accuracy: 0.0325\n",
      "Epoch 343/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0357 - accuracy: 0.0332\n",
      "Epoch 344/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0406 - accuracy: 0.0336\n",
      "Epoch 345/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0392 - accuracy: 0.0352\n",
      "Epoch 346/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0398 - accuracy: 0.0357\n",
      "Epoch 347/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0561 - accuracy: 0.0355\n",
      "Epoch 348/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1512 - accuracy: 0.0338\n",
      "Epoch 349/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1463 - accuracy: 0.0327\n",
      "Epoch 350/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1657 - accuracy: 0.0310\n",
      "Epoch 351/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1665 - accuracy: 0.0304\n",
      "Epoch 352/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1365 - accuracy: 0.0273\n",
      "Epoch 353/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0604 - accuracy: 0.0307\n",
      "Epoch 354/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0473 - accuracy: 0.0350\n",
      "Epoch 355/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0484 - accuracy: 0.0352\n",
      "Epoch 356/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0339 - accuracy: 0.0337\n",
      "Epoch 357/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0519 - accuracy: 0.0347\n",
      "Epoch 358/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0594 - accuracy: 0.0337\n",
      "Epoch 359/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0457 - accuracy: 0.0363\n",
      "Epoch 360/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0664 - accuracy: 0.0347\n",
      "Epoch 361/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0887 - accuracy: 0.0358\n",
      "Epoch 362/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1356 - accuracy: 0.0329\n",
      "Epoch 363/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1085 - accuracy: 0.0312\n",
      "Epoch 364/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1120 - accuracy: 0.0320\n",
      "Epoch 365/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0585 - accuracy: 0.0351\n",
      "Epoch 366/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0427 - accuracy: 0.0343\n",
      "Epoch 367/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0314 - accuracy: 0.0338\n",
      "Epoch 368/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0329 - accuracy: 0.0336\n",
      "Epoch 369/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0243 - accuracy: 0.0348\n",
      "Epoch 370/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0266 - accuracy: 0.0358\n",
      "Epoch 371/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0279 - accuracy: 0.0375\n",
      "Epoch 372/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0370 - accuracy: 0.0364\n",
      "Epoch 373/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0461 - accuracy: 0.0383\n",
      "Epoch 374/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0466 - accuracy: 0.0413\n",
      "Epoch 375/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0854 - accuracy: 0.0391\n",
      "Epoch 376/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0772 - accuracy: 0.0367\n",
      "Epoch 377/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0845 - accuracy: 0.0390\n",
      "Epoch 378/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1553 - accuracy: 0.0365\n",
      "Epoch 379/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1381 - accuracy: 0.0337\n",
      "Epoch 380/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1907 - accuracy: 0.0245\n",
      "Epoch 381/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0905 - accuracy: 0.0299\n",
      "Epoch 382/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1140 - accuracy: 0.0355\n",
      "Epoch 383/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1073 - accuracy: 0.0301\n",
      "Epoch 384/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0826 - accuracy: 0.0324\n",
      "Epoch 385/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0325 - accuracy: 0.0349\n",
      "Epoch 386/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0233 - accuracy: 0.0366\n",
      "Epoch 387/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0206 - accuracy: 0.0367\n",
      "Epoch 388/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0283 - accuracy: 0.0384\n",
      "Epoch 389/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0328 - accuracy: 0.0379\n",
      "Epoch 390/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0286 - accuracy: 0.0385\n",
      "Epoch 391/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0348 - accuracy: 0.0387\n",
      "Epoch 392/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0530 - accuracy: 0.0383\n",
      "Epoch 393/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0389 - accuracy: 0.0381\n",
      "Epoch 394/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0711 - accuracy: 0.0409\n",
      "Epoch 395/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0676 - accuracy: 0.0390\n",
      "Epoch 396/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1232 - accuracy: 0.0359\n",
      "Epoch 397/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0811 - accuracy: 0.0349\n",
      "Epoch 398/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0925 - accuracy: 0.0326\n",
      "Epoch 399/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0630 - accuracy: 0.0339\n",
      "Epoch 400/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0561 - accuracy: 0.0321\n",
      "Epoch 401/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0450 - accuracy: 0.0350\n",
      "Epoch 402/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0389 - accuracy: 0.0368\n",
      "Epoch 403/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0631 - accuracy: 0.0362\n",
      "Epoch 404/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0874 - accuracy: 0.0384\n",
      "Epoch 405/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0738 - accuracy: 0.0403\n",
      "Epoch 406/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1518 - accuracy: 0.0396\n",
      "Epoch 407/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1846 - accuracy: 0.0327\n",
      "Epoch 408/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0930 - accuracy: 0.0346\n",
      "Epoch 409/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0545 - accuracy: 0.0337\n",
      "Epoch 410/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0332 - accuracy: 0.0338\n",
      "Epoch 411/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0292 - accuracy: 0.0366\n",
      "Epoch 412/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0183 - accuracy: 0.0380\n",
      "Epoch 413/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0161 - accuracy: 0.0382\n",
      "Epoch 414/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0167 - accuracy: 0.0388\n",
      "Epoch 415/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0192 - accuracy: 0.0384\n",
      "Epoch 416/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0234 - accuracy: 0.0404\n",
      "Epoch 417/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0507 - accuracy: 0.0402\n",
      "Epoch 418/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0386 - accuracy: 0.0398\n",
      "Epoch 419/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0483 - accuracy: 0.0402\n",
      "Epoch 420/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0507 - accuracy: 0.0406\n",
      "Epoch 421/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0741 - accuracy: 0.0436\n",
      "Epoch 422/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1008 - accuracy: 0.0402\n",
      "Epoch 423/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1512 - accuracy: 0.0332\n",
      "Epoch 424/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.2569 - accuracy: 0.0334\n",
      "Epoch 425/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1717 - accuracy: 0.0314\n",
      "Epoch 426/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1318 - accuracy: 0.0304\n",
      "Epoch 427/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0576 - accuracy: 0.0312\n",
      "Epoch 428/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0345 - accuracy: 0.0355\n",
      "Epoch 429/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0276 - accuracy: 0.0388\n",
      "Epoch 430/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0173 - accuracy: 0.0364\n",
      "Epoch 431/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0165 - accuracy: 0.0352\n",
      "Epoch 432/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0157 - accuracy: 0.0381\n",
      "Epoch 433/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0213 - accuracy: 0.0390\n",
      "Epoch 434/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0218 - accuracy: 0.0409\n",
      "Epoch 435/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0282 - accuracy: 0.0400\n",
      "Epoch 436/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0235 - accuracy: 0.0406\n",
      "Epoch 437/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0239 - accuracy: 0.0413\n",
      "Epoch 438/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0418 - accuracy: 0.0418\n",
      "Epoch 439/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0501 - accuracy: 0.0424\n",
      "Epoch 440/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0898 - accuracy: 0.0401\n",
      "Epoch 441/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0707 - accuracy: 0.0397\n",
      "Epoch 442/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0694 - accuracy: 0.0413\n",
      "Epoch 443/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0605 - accuracy: 0.0424\n",
      "Epoch 444/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0695 - accuracy: 0.0419\n",
      "Epoch 445/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1278 - accuracy: 0.0407\n",
      "Epoch 446/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1707 - accuracy: 0.0380\n",
      "Epoch 447/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1186 - accuracy: 0.0402\n",
      "Epoch 448/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0688 - accuracy: 0.0390\n",
      "Epoch 449/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0423 - accuracy: 0.0393\n",
      "Epoch 450/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0420 - accuracy: 0.0413\n",
      "Epoch 451/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0627 - accuracy: 0.0398\n",
      "Epoch 452/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0780 - accuracy: 0.0393\n",
      "Epoch 453/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0228 - accuracy: 0.0386\n",
      "Epoch 454/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0171 - accuracy: 0.0418\n",
      "Epoch 455/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0187 - accuracy: 0.0436\n",
      "Epoch 456/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0134 - accuracy: 0.0437\n",
      "Epoch 457/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0154 - accuracy: 0.0437\n",
      "Epoch 458/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0188 - accuracy: 0.0456\n",
      "Epoch 459/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0233 - accuracy: 0.0454\n",
      "Epoch 460/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0202 - accuracy: 0.0464\n",
      "Epoch 461/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0188 - accuracy: 0.0483\n",
      "Epoch 462/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0186 - accuracy: 0.0481\n",
      "Epoch 463/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0159 - accuracy: 0.0480\n",
      "Epoch 464/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0277 - accuracy: 0.0501\n",
      "Epoch 465/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0449 - accuracy: 0.0488\n",
      "Epoch 466/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0988 - accuracy: 0.0487\n",
      "Epoch 467/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3513 - accuracy: 0.0411\n",
      "Epoch 468/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.2725 - accuracy: 0.0317\n",
      "Epoch 469/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1372 - accuracy: 0.0338\n",
      "Epoch 470/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0492 - accuracy: 0.0360\n",
      "Epoch 471/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0250 - accuracy: 0.0371\n",
      "Epoch 472/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0209 - accuracy: 0.0401\n",
      "Epoch 473/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0166 - accuracy: 0.0419\n",
      "Epoch 474/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0169 - accuracy: 0.0392\n",
      "Epoch 475/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0194 - accuracy: 0.0416\n",
      "Epoch 476/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0190 - accuracy: 0.0406\n",
      "Epoch 477/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0250 - accuracy: 0.0416\n",
      "Epoch 478/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0159 - accuracy: 0.0430\n",
      "Epoch 479/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0114 - accuracy: 0.0444\n",
      "Epoch 480/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0123 - accuracy: 0.0438\n",
      "Epoch 481/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0194 - accuracy: 0.0446\n",
      "Epoch 482/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0169 - accuracy: 0.0470\n",
      "Epoch 483/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0224 - accuracy: 0.0447\n",
      "Epoch 484/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0153 - accuracy: 0.0461\n",
      "Epoch 485/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0105 - accuracy: 0.0461\n",
      "Epoch 486/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0112 - accuracy: 0.0471\n",
      "Epoch 487/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0154 - accuracy: 0.0478\n",
      "Epoch 488/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0344 - accuracy: 0.0472\n",
      "Epoch 489/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1263 - accuracy: 0.0458\n",
      "Epoch 490/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2054 - accuracy: 0.0383\n",
      "Epoch 491/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.4135 - accuracy: 0.0363\n",
      "Epoch 492/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3266 - accuracy: 0.0257\n",
      "Epoch 493/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0865 - accuracy: 0.0330\n",
      "Epoch 494/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0335 - accuracy: 0.0371\n",
      "Epoch 495/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0160 - accuracy: 0.0360\n",
      "Epoch 496/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0159 - accuracy: 0.0384\n",
      "Epoch 497/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0150 - accuracy: 0.0401\n",
      "Epoch 498/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0300 - accuracy: 0.0405\n",
      "Epoch 499/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0138 - accuracy: 0.0419\n",
      "Epoch 500/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0098 - accuracy: 0.0417\n",
      "Epoch 501/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0147 - accuracy: 0.0433\n",
      "Epoch 502/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0158 - accuracy: 0.0454\n",
      "Epoch 503/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0167 - accuracy: 0.0436\n",
      "Epoch 504/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0401 - accuracy: 0.0447\n",
      "Epoch 505/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0351 - accuracy: 0.0444\n",
      "Epoch 506/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0958 - accuracy: 0.0438\n",
      "Epoch 507/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1412 - accuracy: 0.0447\n",
      "Epoch 508/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1903 - accuracy: 0.0394\n",
      "Epoch 509/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1262 - accuracy: 0.0364\n",
      "Epoch 510/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0618 - accuracy: 0.0381\n",
      "Epoch 511/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0390 - accuracy: 0.0421\n",
      "Epoch 512/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0263 - accuracy: 0.0456\n",
      "Epoch 513/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0128 - accuracy: 0.0449\n",
      "Epoch 514/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0113 - accuracy: 0.0461\n",
      "Epoch 515/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0123 - accuracy: 0.0471\n",
      "Epoch 516/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0158 - accuracy: 0.0478\n",
      "Epoch 517/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0130 - accuracy: 0.0481\n",
      "Epoch 518/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0179 - accuracy: 0.0476\n",
      "Epoch 519/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0164 - accuracy: 0.0502\n",
      "Epoch 520/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0119 - accuracy: 0.0487\n",
      "Epoch 521/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0100 - accuracy: 0.0497\n",
      "Epoch 522/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0116 - accuracy: 0.0499\n",
      "Epoch 523/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0164 - accuracy: 0.0494\n",
      "Epoch 524/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0144 - accuracy: 0.0512\n",
      "Epoch 525/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0091 - accuracy: 0.0519\n",
      "Epoch 526/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0095 - accuracy: 0.0497\n",
      "Epoch 527/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0127 - accuracy: 0.0497\n",
      "Epoch 528/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0131 - accuracy: 0.0509\n",
      "Epoch 529/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0099 - accuracy: 0.0511\n",
      "Epoch 530/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0297 - accuracy: 0.0526\n",
      "Epoch 531/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1334 - accuracy: 0.0524\n",
      "Epoch 532/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3524 - accuracy: 0.0485\n",
      "Epoch 533/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.3051 - accuracy: 0.0293\n",
      "Epoch 534/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1733 - accuracy: 0.0313\n",
      "Epoch 535/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0750 - accuracy: 0.0298\n",
      "Epoch 536/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0350 - accuracy: 0.0375\n",
      "Epoch 537/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0417 - accuracy: 0.0386\n",
      "Epoch 538/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0601 - accuracy: 0.0392\n",
      "Epoch 539/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0323 - accuracy: 0.0418\n",
      "Epoch 540/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0172 - accuracy: 0.0402\n",
      "Epoch 541/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0150 - accuracy: 0.0415\n",
      "Epoch 542/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0149 - accuracy: 0.0434\n",
      "Epoch 543/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0160 - accuracy: 0.0447\n",
      "Epoch 544/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0151 - accuracy: 0.0459\n",
      "Epoch 545/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0115 - accuracy: 0.0441\n",
      "Epoch 546/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0088 - accuracy: 0.0459\n",
      "Epoch 547/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0176 - accuracy: 0.0450\n",
      "Epoch 548/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0295 - accuracy: 0.0457\n",
      "Epoch 549/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0155 - accuracy: 0.0468\n",
      "Epoch 550/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0203 - accuracy: 0.0463\n",
      "Epoch 551/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0173 - accuracy: 0.0481\n",
      "Epoch 552/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0118 - accuracy: 0.0482\n",
      "Epoch 553/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0175 - accuracy: 0.0492\n",
      "Epoch 554/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0901 - accuracy: 0.0436\n",
      "Epoch 555/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1604 - accuracy: 0.0441\n",
      "Epoch 556/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1457 - accuracy: 0.0380\n",
      "Epoch 557/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1665 - accuracy: 0.0372\n",
      "Epoch 558/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2429 - accuracy: 0.0396\n",
      "Epoch 559/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1009 - accuracy: 0.0348\n",
      "Epoch 560/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0569 - accuracy: 0.0402\n",
      "Epoch 561/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0408 - accuracy: 0.0407\n",
      "Epoch 562/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0192 - accuracy: 0.0450\n",
      "Epoch 563/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0113 - accuracy: 0.0420\n",
      "Epoch 564/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0106 - accuracy: 0.0448\n",
      "Epoch 565/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0066 - accuracy: 0.0480\n",
      "Epoch 566/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0061 - accuracy: 0.0476\n",
      "Epoch 567/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0102 - accuracy: 0.0476\n",
      "Epoch 568/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0090 - accuracy: 0.0495\n",
      "Epoch 569/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0070 - accuracy: 0.0487\n",
      "Epoch 570/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0056 - accuracy: 0.0501\n",
      "Epoch 571/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0052 - accuracy: 0.0521\n",
      "Epoch 572/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0077 - accuracy: 0.0527\n",
      "Epoch 573/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0100 - accuracy: 0.0526\n",
      "Epoch 574/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0102 - accuracy: 0.0526\n",
      "Epoch 575/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0104 - accuracy: 0.0516\n",
      "Epoch 576/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0091 - accuracy: 0.0540\n",
      "Epoch 577/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0107 - accuracy: 0.0533\n",
      "Epoch 578/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0320 - accuracy: 0.0522\n",
      "Epoch 579/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0343 - accuracy: 0.0525\n",
      "Epoch 580/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0601 - accuracy: 0.0518\n",
      "Epoch 581/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0881 - accuracy: 0.0549\n",
      "Epoch 582/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.4887 - accuracy: 0.0384\n",
      "Epoch 583/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3384 - accuracy: 0.0298\n",
      "Epoch 584/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1959 - accuracy: 0.0343\n",
      "Epoch 585/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0656 - accuracy: 0.0375\n",
      "Epoch 586/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0314 - accuracy: 0.0421\n",
      "Epoch 587/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0242 - accuracy: 0.0399\n",
      "Epoch 588/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0127 - accuracy: 0.0420\n",
      "Epoch 589/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0086 - accuracy: 0.0437\n",
      "Epoch 590/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0080 - accuracy: 0.0457\n",
      "Epoch 591/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0072 - accuracy: 0.0451\n",
      "Epoch 592/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0061 - accuracy: 0.0463\n",
      "Epoch 593/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0078 - accuracy: 0.0480\n",
      "Epoch 594/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0079 - accuracy: 0.0468\n",
      "Epoch 595/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0088 - accuracy: 0.0485\n",
      "Epoch 596/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0113 - accuracy: 0.0477\n",
      "Epoch 597/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0082 - accuracy: 0.0480\n",
      "Epoch 598/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0162 - accuracy: 0.0503\n",
      "Epoch 599/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0261 - accuracy: 0.0504\n",
      "Epoch 600/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0387 - accuracy: 0.0481\n",
      "Epoch 601/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0964 - accuracy: 0.0473\n",
      "Epoch 602/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1956 - accuracy: 0.0414\n",
      "Epoch 603/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.3503 - accuracy: 0.0387\n",
      "Epoch 604/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1204 - accuracy: 0.0300\n",
      "Epoch 605/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0341 - accuracy: 0.0409\n",
      "Epoch 606/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0133 - accuracy: 0.0424\n",
      "Epoch 607/3000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0089 - accuracy: 0.0434\n",
      "Epoch 608/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0086 - accuracy: 0.0447\n",
      "Epoch 609/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0079 - accuracy: 0.0446\n",
      "Epoch 610/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0090 - accuracy: 0.0468\n",
      "Epoch 611/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0085 - accuracy: 0.0471\n",
      "Epoch 612/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0152 - accuracy: 0.0484\n",
      "Epoch 613/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0086 - accuracy: 0.0494\n",
      "Epoch 614/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0053 - accuracy: 0.0504\n",
      "Epoch 615/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0075 - accuracy: 0.0499\n",
      "Epoch 616/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0215 - accuracy: 0.0509\n",
      "Epoch 617/3000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0171 - accuracy: 0.0505\n",
      "Epoch 618/3000\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0058 - accuracy: 0.0523"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb Cella 28\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m epochs\u001b[39m=\u001b[39m\u001b[39m3000\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m batch_size\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/davidemolitierno/Repositories/MDLProj/gallo.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nn\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda/envs/dlenv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=3000\n",
    "batch_size=50\n",
    "nn.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e21d7e22773fa04c0c154aba3df5d14f691f6a46c7c50a4150a0567bbfb05b29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
