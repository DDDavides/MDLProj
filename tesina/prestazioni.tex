Infine, analizzando le prestazioni e confrontandole tra di loro, si nota come un approccio di tipo Machine Learning porti a risultati non soddisfacenti. Invece, con un approccio Deep (ad esempio applicando la WaveNet), le performance migliorano notevolmente e si evita anche il fenomeno dell'overfitting. 

Di seguito viene mostrata la tabella riassuntiva delle prestazioni relative alle architetture utilizzate e presentate nella sezione precedente.
\definecolor{maroon}{cmyk}{0,0.75,0.71,0}
\definecolor{gre}{cmyk}{0.68,0,0.75,0.29}
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|}
    \hline
         \textbf{Model} & \textbf{Train Accuracy} & \textbf{Test Accuracy} \\
    \hline 
        \rowcolor{maroon!70} Random Forest & 0.429 &  0.418 \\
    \hline
        Rete neurale & 0.521 & 0.531 \\
    \hline
        \rowcolor{gre!50} SimpleRNN & 0.569 & 0.598 \\
    \hline
        \rowcolor{gre!50} LSTM & 0.587 & 0.595 \\
    \hline
        LSTM (time steps = features) & 0.540 & 0.570 \\
    \hline
        GRU & 0.604 & 0.588 \\
    \hline
        \rowcolor{maroon!70} Bidirectional & 0.741 & 0.549 \\
    \hline
        WaveNet & 0.608 & 0.582 \\
    \hline
    \end{tabular}
    \caption{Prestazione delle architetture utilizzate a confronto, in rosso le peggiori ed in verde le migliori}
    \label{tab:prestazioni}
\end{table}

In conclusione, le architetture migliori risultano essere la WaveNet e quelle ricorrenti (in particolare contenenti layer LSTM, GRU o SimpleRNN); per incrementare ulteriormente le prestazioni bisognerebbe migliorare la qualità del dataset utilizzato, aumentando il numero di partite a disposizione ed introducendo, per ciascuna di queste, ulteriori features come i tiri in porta di ciascuna squadra, la disponibilità dei giocatori migliori al momento della partita e così via.