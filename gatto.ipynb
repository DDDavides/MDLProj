{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from tensorflow import keras as k\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# %pip install d2l==1.0.0a1.post0\n",
    "from d2l import tensorflow as d2l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./input/dataset.csv')\n",
    "# dataImputed = pd.read_csv('./input/datasetImputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è stata riscritta una funzione di reshape inutile \n",
    "# e.g. (a_prev=x_train, season=trn_ssn)\n",
    "def reshape_to_inputshape(a_prev,season):\n",
    "    totalMatches = len(season)*38\n",
    "    input_step = int(a_prev.shape[0]/totalMatches)\n",
    "    prev_f = a_prev.shape[1]\n",
    "    return np.reshape(a_prev, (totalMatches, input_step, prev_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['HomeTeam', 'AwayTeam', \n",
    "            'HTeamEloScore', 'ATeamEloScore', \n",
    "            'HTdaysSinceLastMatch', 'ATdaysSinceLastMatch', \n",
    "            'HTW_rate', 'ATW_rate', 'ATD_rate', 'HTD_rate', \n",
    "            '7_HTW_rate', '12_HTW_rate', '7_ATW_rate', '12_ATW_rate', \n",
    "            '7_HTD_rate', '12_HTD_rate', '7_ATD_rate', '12_ATD_rate',\n",
    "            '7_HTL_rate', '12_HTL_rate', '7_ATL_rate', '12_ATL_rate',\n",
    "            '5_HTHW_rate', '5_ATAW_rate']\n",
    "\n",
    "X = pd.get_dummies(data[features])\n",
    "\n",
    "# Se non cambiamo nulla il OneHotEncoder assegna:\n",
    "# A -> 1 0 0\n",
    "# D -> 0 1 0\n",
    "# H -> 0 0 1\n",
    "y = data[['FTR']].to_numpy().ravel().reshape(-1, 1)\n",
    "y = OneHotEncoder(sparse=False).fit_transform(y)\n",
    "X_imputed = SimpleImputer().fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è stata riscritta una funzione di reshape inutile \n",
    "# e.g. (a_prev=x_train, season=trn_ssn)\n",
    "def reshape_to_inputshape(a_prev,season):\n",
    "    totalMatches = len(season)*38\n",
    "    input_step = int(a_prev.shape[0]/totalMatches)\n",
    "    prev_f = a_prev.shape[1]\n",
    "    return np.reshape(a_prev, (totalMatches, input_step, prev_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(304, 10, 118)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/davidegattini/SourceTreeProj/MDLProj/gatto.ipynb Cella 6\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidegattini/SourceTreeProj/MDLProj/gatto.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(data, y, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, test_size\u001b[39m=\u001b[39mtest_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidegattini/SourceTreeProj/MDLProj/gatto.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#Setup XY to have 10 game steps\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/davidegattini/SourceTreeProj/MDLProj/gatto.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m x_train \u001b[39m=\u001b[39m reshape_to_inputshape(x_train,trn_ssn)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidegattini/SourceTreeProj/MDLProj/gatto.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y_train \u001b[39m=\u001b[39m reshape_to_inputshape(y_train,trn_ssn)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidegattini/SourceTreeProj/MDLProj/gatto.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmoveaxis(y_train, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/Users/davidegattini/SourceTreeProj/MDLProj/gatto.ipynb Cella 6\u001b[0m in \u001b[0;36mreshape_to_inputshape\u001b[0;34m(a_prev, season)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidegattini/SourceTreeProj/MDLProj/gatto.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m input_step \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(a_prev\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m/\u001b[39mtotalMatches)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidegattini/SourceTreeProj/MDLProj/gatto.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m prev_f \u001b[39m=\u001b[39m a_prev\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/davidegattini/SourceTreeProj/MDLProj/gatto.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mreshape(a_prev, (totalMatches, input_step, prev_f))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl/lib/python3.8/site-packages/numpy/core/fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    200\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl/lib/python3.8/site-packages/numpy/core/fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m bound \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, method, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m bound \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl/lib/python3.8/site-packages/numpy/core/fromnumeric.py:47\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m     46\u001b[0m         result \u001b[39m=\u001b[39m asarray(result)\n\u001b[0;32m---> 47\u001b[0m     result \u001b[39m=\u001b[39m wrap(result)\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl/lib/python3.8/site-packages/pandas/core/generic.py:2107\u001b[0m, in \u001b[0;36mNDFrame.__array_wrap__\u001b[0;34m(self, result, context)\u001b[0m\n\u001b[1;32m   2105\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m   2106\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_axes_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_AXIS_ORDERS, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 2107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(res, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49md)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__array_wrap__\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl/lib/python3.8/site-packages/pandas/core/frame.py:720\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    710\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    711\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    712\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    717\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    718\u001b[0m         )\n\u001b[1;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    721\u001b[0m             data,\n\u001b[1;32m    722\u001b[0m             index,\n\u001b[1;32m    723\u001b[0m             columns,\n\u001b[1;32m    724\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    725\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    726\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    727\u001b[0m         )\n\u001b[1;32m    729\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl/lib/python3.8/site-packages/pandas/core/internals/construction.py:329\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    324\u001b[0m         values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     \u001b[39m# by definition an array here\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     \u001b[39m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     values \u001b[39m=\u001b[39m _prep_ndarraylike(values, copy\u001b[39m=\u001b[39;49mcopy_on_sanitize)\n\u001b[1;32m    331\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dtype_equal(values\u001b[39m.\u001b[39mdtype, dtype):\n\u001b[1;32m    332\u001b[0m     \u001b[39m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     rcf \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m (is_integer_dtype(dtype) \u001b[39mand\u001b[39;00m values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl/lib/python3.8/site-packages/pandas/core/internals/construction.py:583\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    581\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape((values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m))\n\u001b[1;32m    582\u001b[0m \u001b[39melif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 583\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMust pass 2-d input. shape=\u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    585\u001b[0m \u001b[39mreturn\u001b[39;00m values\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=(304, 10, 118)"
     ]
    }
   ],
   "source": [
    "trn_ssn = [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]\n",
    "trn_ssn_len = len(trn_ssn)\n",
    "tst_ssn = [2016,2017,2018] \n",
    "tst_ssn_len = len(tst_ssn)\n",
    "\n",
    "\n",
    "\n",
    "test_size = float(tst_ssn_len)/(tst_ssn_len+trn_ssn_len)\n",
    "#Split X and Y into training and Test Sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, y, shuffle=False, test_size=test_size)\n",
    "\n",
    "#Setup XY to have 10 game steps\n",
    "x_train = reshape_to_inputshape(x_train,trn_ssn)\n",
    "\n",
    "y_train = reshape_to_inputshape(y_train,trn_ssn)\n",
    "y_train = np.moveaxis(y_train, 0, 1)\n",
    "x_test = reshape_to_inputshape(x_test,tst_ssn)\n",
    "y_test = reshape_to_inputshape(y_test,tst_ssn)\n",
    "y_test = np.moveaxis(y_test, 0, 1)\n",
    "\n",
    "Tx= x_train.shape[1] #Time steps\n",
    "Ty= y_train.shape[0] #Time Steps\n",
    "num_features = x_train.shape[2] #Features per step\n",
    "\n",
    "inputs = tf.keras.Input(shape=(Tx, num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = tf.keras.models.Sequential([\n",
    "    # tf.keras.Input(shape=(Tx, num_features)),\n",
    "    # k.layers.Lambda(lambda z: inputs[:, 1, :]),\n",
    "    k.layers.Flatten(),\n",
    "    k.layers.Dense(4000),\n",
    "    k.layers.Dense(240),\n",
    "    k.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001)\n",
    "#    ,metrics=[tf.keras.metrics.Accuracy()]\n",
    ")\n",
    "lst(x_train)\n",
    "lst.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessamento dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from IPython.display import display\n",
    "\n",
    "#Create X and Y\n",
    "X = pd.get_dummies(data[['HomeTeam', 'AwayTeam', 'HTeamEloScore', 'ATeamEloScore', 'HTdaysSinceLastMatch',\n",
    "                            'ATdaysSinceLastMatch', 'HTW_rate', 'ATW_rate',\n",
    "                            'ATD_rate', 'HTD_rate', \n",
    "                '7_HTW_rate', '12_HTW_rate', '7_ATW_rate', '12_ATW_rate', \n",
    "                '7_HTD_rate', '12_HTD_rate', '7_ATD_rate', '12_ATD_rate',\n",
    "                '7_HTL_rate', '12_HTL_rate', '7_ATL_rate', '12_ATL_rate',\n",
    "                '5_HTHW_rate', '5_ATAW_rate']])\n",
    "Y = data[['FTR']]\n",
    "\n",
    "#X preprocessing\n",
    "imputer = SimpleImputer()\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "#Split X and Y into training and Test Sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_imputed, Y, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Logistic Regression Model Setup\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Logistic Regression Model Metrics\n",
    "print(\"Logestic Regression\")\n",
    "print(\"Train Score: \", model.score(x_train, y_train))\n",
    "print(\"Test Score: \", model.score(x_test, y_test))\n",
    "print(classification_report(y_test, model.predict(x_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forest model setup\n",
    "forest = RandomForestClassifier(n_estimators=2, random_state=2)\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "#Forest Model Metrics\n",
    "print(\"Forest Classifier\")\n",
    "print(\"Train Score: \", forest.score(x_train, y_train))\n",
    "print(\"Test Score: \", forest.score(x_test, y_test))\n",
    "print(classification_report(y_test, forest.predict(x_test), digits=3))\n",
    "\n",
    "print(y_test.shape)\n",
    "print(forest.predict(x_test).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "#make TF work like the TF in the HWs\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "Y = data[['ordinalHR']]\n",
    "print(Y)\n",
    "Y = data[['ordinalHR']].to_numpy().ravel()*2\n",
    "print(Y)\n",
    "\n",
    "#Neural Network Setup\n",
    "n_inputs = X.shape[1]\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 3\n",
    "\n",
    "#Tensorflow X and Y\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_inputs), name = 'X')\n",
    "Y = tf.placeholder(tf.int32, shape = (None), name = 'Y')\n",
    "\n",
    "#Function used to better display model metrics\n",
    "def convert_ordinalHR(x):\n",
    "    y=[]\n",
    "    for i in range(x.size):\n",
    "        if x[i] == 0:\n",
    "            y.append('A')\n",
    "        elif x[i] == 2:\n",
    "            y.append('H')\n",
    "        elif x[i] == 1:\n",
    "            y.append('D')\n",
    "    return y\n",
    "\n",
    "#General Function for neural layer setup\n",
    "def neuron_layer(X, n_neurons, name, activation = None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs + n_neurons)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name = 'kernel')\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name='bias')\n",
    "        L2 = tf.nn.l2_loss(W)\n",
    "        Z = tf.matmul(X,W)+b\n",
    "        if activation is not None:\n",
    "            return activation(Z), L2\n",
    "        else:\n",
    "            return Z, L2\n",
    "\n",
    "#Tensorflow neural layer setup\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1, L2_1 = neuron_layer(X, n_hidden1, name='hidden1', activation=tf.nn.relu)\n",
    "    hidden2, L2_2 = neuron_layer(hidden1, n_hidden2, name='hidden2', activation=tf.nn.relu)\n",
    "    logits, L2_3 = neuron_layer(hidden2, n_outputs, name='outputs', activation=None)\n",
    "\n",
    "#Loss function\n",
    "beta=0.01\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = Y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy+beta*(L2_1+L2_2+L2_3), name='loss')\n",
    "    \n",
    "#Optimizer\n",
    "learning_rate = 0.000001\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "#Metric analysis setup\n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, Y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    preds = tf.argmax(input=logits, axis=1)\n",
    "    \n",
    "#Initialize the above tensorflow variables    \n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#Runtime and batchsetup\n",
    "n_epochs = 30000\n",
    "batch_size = 50\n",
    "\n",
    "#Run the model\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    #Model Loop\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={X: x_train, Y: y_train})\n",
    "        acc_train = accuracy.eval(feed_dict={X: x_train, Y: y_train})\n",
    "        acc_val = accuracy.eval(feed_dict={X: x_test, Y: y_test})\n",
    "        if(epoch % 200 == 0 or epoch==n_epochs-1):\n",
    "            print(epoch, 'Train accuracy:', acc_train, 'Val accuracy:', acc_val)\n",
    "    \n",
    "    #Retrive Metrics\n",
    "    acc_val = accuracy.eval(feed_dict={X: x_test, Y: y_test})\n",
    "    preds = preds.eval(feed_dict = {X:x_test})\n",
    "    log = logits.eval(feed_dict = {X:x_test})\n",
    "    preds=convert_ordinalHR(preds)\n",
    "    y_test=convert_ordinalHR(y_test)\n",
    "    \n",
    "    #Print Metrics\n",
    "    print('Train accuracy:', acc_train, 'Val accuracy:', acc_val)\n",
    "    print(classification_report(y_test, preds, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provare altre architetture deep, magari altre RNN (e.g., GRU, bidirectional, deep RNN, ...) e vedere se si comportano meglio o peggio della LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "m = 5\n",
    "\n",
    "for (x,y) in [(i,j) for i in range(n) for j in range(m)]:\n",
    "    print(f\"(\",x,y,\")\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = k.layers.Input(shape=(10,94))\n",
    "lstm1 = k.layers.LSTM(100, return_sequences=True)(inputs)\n",
    "lstm2 = k.layers.LSTM(50, return_sequences=True)(inputs)\n",
    "concateneted = k.layers.Concatenate()([\n",
    "    lstm1,\n",
    "    lstm2\n",
    "])\n",
    "\n",
    "out = k.layers.Dropout(0.5)(concateneted)\n",
    "out = k.layers.Dense(1000, activation=\"relu\")(out)\n",
    "out = k.layers.Dropout(0.5)(out)\n",
    "out = k.layers.Dense(250, activation=\"relu\")(out)\n",
    "out = k.layers.Dropout(0.5)(out)\n",
    "out = k.layers.Dense(3, activation=\"softmax\")(out)\n",
    "\n",
    "model = k.models.Model(inputs=inputs, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "model.fit(x_prova, y_prova, epochs=500, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_prova_test, y_prova_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_yoh(Y):\n",
    "    Y_new = np.empty([Y.shape[0],Y.shape[1]], dtype=\"<U1\")\n",
    "    #Y_new = np.zeros((Y.shape[0],Y.shape[1]))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if (Y[i, j] == 0):\n",
    "                Y_new[i, j]= 'A'\n",
    "            elif (Y[i, j] == 1):\n",
    "                Y_new[i, j]= 'D'\n",
    "            elif (Y[i, j] == 2):\n",
    "                Y_new[i, j]='H'\n",
    "    return Y_new\n",
    "\n",
    "y_pred = model.predict(x_prova_test)\n",
    "y_predm = np.asarray(y_pred)\n",
    "y_predm = np.argmax(y_predm, axis=2)\n",
    "y_testm = np.argmax(y_prova_test, axis=2)\n",
    "\n",
    "y_pred_train = model.predict(x_prova)\n",
    "y_pred_train = np.asarray(y_pred_train)\n",
    "y_predm_train = np.argmax(y_pred_train, axis=2)\n",
    "y_trainm = np.argmax(y_prova, axis = 2)\n",
    "\n",
    "y_predm = revert_yoh(y_predm).ravel()\n",
    "y_testm = revert_yoh(y_testm).ravel()\n",
    "\n",
    "y_predm_train = revert_yoh(y_predm_train).ravel()\n",
    "y_trainm = revert_yoh(y_trainm).ravel()\n",
    "\n",
    "#Model Metrics\n",
    "print(classification_report(y_testm, y_predm, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2b3490ab97e9e12756aa89c01d5382ca6cf08cdaa9c454d9749392520b38d26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
